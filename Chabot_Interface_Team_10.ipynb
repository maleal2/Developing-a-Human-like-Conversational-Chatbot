{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1XrJvvyQFHZJLjlH_jJVRvVMidVPAr8aV",
      "authorship_tag": "ABX9TyPO6DYxZFMXjl3lDsmgq4UM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maleal2/Developing-a-Human-like-Conversational-Chatbot/blob/main/Chabot_Interface_Team_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Developing a Human-like Conversational Chatbot**\n",
        "\n",
        "Maria Carolina Leal Cardenas\n",
        "\n",
        "Department of Graduate Studies-Engineering, University of San Diego\n",
        "\n",
        "**Natural Language Processing and GenAI (AAI-520-04)**\n"
      ],
      "metadata": {
        "id": "qDEMzXpUe7Ob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions on runing the code for Chatbot Interface\n",
        "\n",
        "1. Run \"Setting up Environment\".\n",
        "2. Run \"Importing necessary Libraries\".\n",
        "3. Run \"Gradio Chatbot Interface\".\n",
        "\n",
        "Once you run all the code cells in order you will receive a prompt and a valid link to access via web-browser to the ChatBot API interface."
      ],
      "metadata": {
        "id": "pOJ1-KFiUi-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Environment."
      ],
      "metadata": {
        "id": "KrFdUPiqjtfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets\n"
      ],
      "metadata": {
        "id": "AbcxB_eU5nso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "id": "eiFoeSZkRbYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n"
      ],
      "metadata": {
        "id": "Fle4u5TJHdkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries."
      ],
      "metadata": {
        "id": "uUI12Poh8bie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "# Operating System and File I/O Libraries\n",
        "# -------------------------------------------\n",
        "\n",
        "import os  # Provides a way of using operating system dependent functionality like reading or writing to the file system.\n",
        "import zipfile  # Provides a tool to create, read, write, append, and list a ZIP file.\n",
        "import csv  # Used to read from and write to CSV (Comma-Separated Values) files.\n",
        "import urllib.request  # Allows for fetching data across the web (e.g., downloading files).\n",
        "import pickle  # Serializes and deserializes Python object structures.\n",
        "\n",
        "# -------------------------------------------\n",
        "# Data Processing and Manipulation Libraries\n",
        "# -------------------------------------------\n",
        "\n",
        "import pandas as pd  # Provides data structures and data analysis tools.\n",
        "import numpy as np  # Supports large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
        "\n",
        "# -------------------------------------------\n",
        "# Regular Expressions and Data Counting Libraries\n",
        "# -------------------------------------------\n",
        "\n",
        "import re  # Provides regular expression matching operations.\n",
        "from collections import Counter  # A dict subclass for counting hashable objects.\n",
        "\n",
        "# -------------------------------------------\n",
        "# PyTorch Libraries (Deep Learning)\n",
        "# -------------------------------------------\n",
        "\n",
        "import torch  # Core PyTorch library for tensor operations.\n",
        "import torch.nn as nn  # Contains neural network layers, functions, and losses.\n",
        "import torch.optim as optim  # Implements various optimization algorithms.\n",
        "from torch.utils.data import DataLoader  # Provides tools to load datasets in batches for training.\n",
        "import math  # Provides mathematical functions like exp, log, sqrt, etc.\n",
        "\n",
        "# -------------------------------------------\n",
        "# Hugging Face Transformers Libraries\n",
        "# -------------------------------------------\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments  # For fine-tuning and working with transformer models like GPT-2.\n",
        "from datasets import Dataset, load_from_disk  # Provides tools for loading and managing datasets for machine learning.\n",
        "\n",
        "# -------------------------------------------\n",
        "# Visualization Libraries\n",
        "# -------------------------------------------\n",
        "\n",
        "import matplotlib.pyplot as plt  # For creating static, animated, and interactive visualizations in Python.\n",
        "\n",
        "# -------------------------------------------\n",
        "# Progress Monitoring Libraries\n",
        "# -------------------------------------------\n",
        "\n",
        "from tqdm import tqdm  # Allows for displaying progress bars during loops or long computations.\n",
        "\n",
        "# -------------------------------------------\n",
        "# User Interface (Gradio)\n",
        "# -------------------------------------------\n",
        "\n",
        "import gradio as gr  # Library for building user interfaces in Python.\n"
      ],
      "metadata": {
        "id": "pi_QRMvd8eQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Chatbot Interface."
      ],
      "metadata": {
        "id": "WpkzmmTH6HMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "# Load Tokenizer and Model from Checkpoint\n",
        "# -------------------------------------------\n",
        "model_output_dir = \"GohanF2/Developing-a-Human-like-Conversational-Chatbot\"\n",
        "\n",
        "# Load the fine-tuned model and tokenizer from the checkpoint\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_output_dir)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_output_dir)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# -------------------------------------------\n",
        "# Define Conversation History and Generation Parameters\n",
        "# -------------------------------------------\n",
        "conversation_history = \"\"  # Keep track of conversation history\n",
        "temperature = 0.8  # For more creative responses\n",
        "top_k = 50  # Top-K sampling for limiting random word choices\n",
        "max_new_tokens = 50  # Limit the number of newly generated tokens\n",
        "max_length = 100  # Max total length for response\n",
        "min_length = 10  # Minimum number of tokens in the response\n",
        "repetition_penalty = 1.2  # Penalize repetition\n",
        "\n",
        "# Define max token length for conversation history\n",
        "max_history_tokens = 300  # Limit conversation history to the last 300 tokens\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# Function to Trim Conversation History\n",
        "# -------------------------------------------\n",
        "def trim_conversation_history():\n",
        "    global conversation_history\n",
        "    tokenized_history = tokenizer.encode(conversation_history)\n",
        "\n",
        "    if len(tokenized_history) > max_history_tokens:\n",
        "        # Keep only the last `max_history_tokens` worth of tokens\n",
        "        trimmed_history = tokenizer.decode(tokenized_history[-max_history_tokens:], skip_special_tokens=True)\n",
        "        conversation_history = trimmed_history\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# Function to Generate a Single Response\n",
        "# -------------------------------------------\n",
        "def chatbot_response(prompt):\n",
        "    # Tokenize the prompt and create attention mask\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    attention_mask = torch.ones(inputs.shape, device=device)  # Create attention mask\n",
        "\n",
        "    # Generate response with the adjusted parameters\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        attention_mask=attention_mask,  # Pass the attention mask\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        temperature=temperature,\n",
        "        top_k=top_k,\n",
        "        min_length=min_length,  # Ensure responses are at least 10 tokens long\n",
        "        max_length=max_length,  # Avoid responses longer than 100 tokens\n",
        "        pad_token_id=tokenizer.eos_token_id,  # Set EOS token as the pad token\n",
        "        no_repeat_ngram_size=2,  # Avoid repetitive n-grams\n",
        "        repetition_penalty=repetition_penalty,  # Apply repetition penalty\n",
        "        do_sample=True,  # Enable sampling to use temperature\n",
        "    )\n",
        "\n",
        "    # Decode and return the response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# Function to Generate a Response with Conversation History\n",
        "# -------------------------------------------\n",
        "def generate_conversational_response(user_input):\n",
        "    global conversation_history\n",
        "    # Add user input to conversation history\n",
        "    conversation_history += f\"User: {user_input}\\nAI: \"\n",
        "\n",
        "    # Trim conversation history to avoid excessive length\n",
        "    trim_conversation_history()\n",
        "\n",
        "    # Generate the chatbot's response\n",
        "    response = chatbot_response(conversation_history)\n",
        "    conversation_history += response + \"\\n\"  # Update conversation history\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# Function to Reset the Conversation\n",
        "# -------------------------------------------\n",
        "def reset_conversation():\n",
        "    global conversation_history\n",
        "    conversation_history = \"\"\n",
        "    return \"Conversation reset.\"\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# Gradio Interface for the Chatbot\n",
        "# -------------------------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot_input = gr.Textbox(label=\"Chatbot Interface\", placeholder=\"Talk to the chatbot\", lines=2)\n",
        "    send_button = gr.Button(\"Send\")\n",
        "\n",
        "    output_box = gr.Textbox(label=\"Chatbot Response\", placeholder=\"Chatbot will respond here\", lines=3)\n",
        "\n",
        "    reset_button = gr.Button(\"Reset Conversation\")\n",
        "\n",
        "    # Set up event handling for sending message\n",
        "    send_button.click(generate_conversational_response, inputs=chatbot_input, outputs=output_box)\n",
        "\n",
        "    # Set up event handling for resetting conversation\n",
        "    reset_button.click(fn=reset_conversation, outputs=output_box)\n",
        "\n",
        "# Launch the interface with sharing enabled\n",
        "demo.launch(share=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "hgXZolbHRX9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}